{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56af74e9",
   "metadata": {},
   "source": [
    "# Edge AI Prototype: Recyclable Item Classification üå±‚ôªÔ∏è\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a complete Edge AI pipeline for real-time recyclable item classification. We'll build a lightweight model suitable for deployment on edge devices like Raspberry Pi or mobile phones.\n",
    "\n",
    "### Learning Objectives:\n",
    "1. **Understand Edge AI principles** and benefits over cloud-based processing\n",
    "2. **Build and optimize** a lightweight image classification model\n",
    "3. **Convert to TensorFlow Lite** for edge deployment\n",
    "4. **Analyze performance metrics** including accuracy, latency, and model size\n",
    "5. **Simulate edge deployment** scenarios\n",
    "\n",
    "### Real-World Application:\n",
    "Smart waste management systems that can automatically sort recyclables in real-time, reducing contamination and improving recycling efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Structure:\n",
    "1. **Data Preparation** - Create and preprocess recyclable item dataset\n",
    "2. **Model Development** - Build efficient CNN architecture\n",
    "3. **TensorFlow Lite Conversion** - Optimize for edge deployment\n",
    "4. **Performance Analysis** - Evaluate metrics and deployment readiness\n",
    "5. **Edge Simulation** - Demonstrate real-time capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries and Setup\n",
    "import tensorflow as tf\n",
    "import tensorflow.lite as tflite\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üöÄ Edge AI Development Environment Ready!\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Available GPUs: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "\n",
    "# Check TensorFlow Lite availability\n",
    "try:\n",
    "    interpreter = tf.lite.Interpreter(model_content=b'')\n",
    "    print(\"‚úÖ TensorFlow Lite is available\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è TensorFlow Lite initialization check failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d90229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation and Synthetic Dataset Creation\n",
    "print(\"üìä Creating Synthetic Recyclable Items Dataset...\")\n",
    "\n",
    "# Define recyclable categories\n",
    "CATEGORIES = ['plastic_bottle', 'aluminum_can', 'paper', 'glass', 'cardboard']\n",
    "IMG_SIZE = 96  # Smaller size for edge deployment\n",
    "NUM_SAMPLES_PER_CLASS = 200\n",
    "\n",
    "def create_synthetic_image(category, img_id):\n",
    "    \"\"\"\n",
    "    Create synthetic images with distinctive patterns for each recyclable type\n",
    "    \"\"\"\n",
    "    np.random.seed(img_id + hash(category) % 1000)\n",
    "    \n",
    "    # Base image\n",
    "    img = np.random.randint(0, 50, (IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "    \n",
    "    if category == 'plastic_bottle':\n",
    "        # Add cylindrical pattern and transparency effect\n",
    "        center_x, center_y = IMG_SIZE // 2, IMG_SIZE // 2\n",
    "        for i in range(IMG_SIZE):\n",
    "            for j in range(IMG_SIZE):\n",
    "                dist = np.sqrt((i - center_x)**2 + (j - center_y)**2)\n",
    "                if dist < IMG_SIZE // 3:\n",
    "                    img[i, j] = [100 + int(30 * np.sin(dist/5)), 150, 200]\n",
    "    \n",
    "    elif category == 'aluminum_can':\n",
    "        # Add metallic pattern\n",
    "        for i in range(0, IMG_SIZE, 8):\n",
    "            img[i:i+4, :] = [180, 180, 190]\n",
    "        img += np.random.randint(-20, 20, img.shape)\n",
    "    \n",
    "    elif category == 'paper':\n",
    "        # Add texture and white color\n",
    "        img[:, :] = [240, 240, 235]\n",
    "        # Add some text-like patterns\n",
    "        for i in range(10, IMG_SIZE-10, 15):\n",
    "            img[i:i+2, 10:IMG_SIZE-10] = [50, 50, 50]\n",
    "        img += np.random.randint(-15, 15, img.shape)\n",
    "    \n",
    "    elif category == 'glass':\n",
    "        # Add transparent/reflective pattern\n",
    "        img[:, :] = [220, 240, 250]\n",
    "        # Add reflection lines\n",
    "        for i in range(0, IMG_SIZE, 12):\n",
    "            img[:, i:i+2] = [255, 255, 255]\n",
    "        img += np.random.randint(-10, 10, img.shape)\n",
    "    \n",
    "    elif category == 'cardboard':\n",
    "        # Add brown corrugated pattern\n",
    "        img[:, :] = [160, 120, 80]\n",
    "        # Add corrugated lines\n",
    "        for i in range(0, IMG_SIZE, 6):\n",
    "            img[i:i+3, :] = [180, 140, 100]\n",
    "        img += np.random.randint(-25, 25, img.shape)\n",
    "    \n",
    "    # Ensure values are in valid range\n",
    "    img = np.clip(img, 0, 255)\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for idx, category in enumerate(CATEGORIES):\n",
    "    print(f\"  Generating {category} images...\")\n",
    "    for i in range(NUM_SAMPLES_PER_CLASS):\n",
    "        img = create_synthetic_image(category, i)\n",
    "        X_data.append(img)\n",
    "        y_data.append(idx)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "print(f\"‚úÖ Dataset created: {X_data.shape[0]} images, {len(CATEGORIES)} categories\")\n",
    "print(f\"   Image dimensions: {X_data.shape[1:3]}\")\n",
    "print(f\"   Categories: {CATEGORIES}\")\n",
    "\n",
    "# Visualize sample images\n",
    "fig, axes = plt.subplots(1, len(CATEGORIES), figsize=(15, 3))\n",
    "for i, (ax, category) in enumerate(zip(axes, CATEGORIES)):\n",
    "    sample_img = X_data[y_data == i][0]\n",
    "    ax.imshow(sample_img)\n",
    "    ax.set_title(f\"{category.replace('_', ' ').title()}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Sample Recyclable Items (Synthetic Dataset)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Data preprocessing\n",
    "X_data = X_data.astype('float32') / 255.0  # Normalize to [0,1]\n",
    "y_data = tf.keras.utils.to_categorical(y_data, len(CATEGORIES))\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, test_size=0.2, random_state=42, stratify=y_data\n",
    ")\n",
    "\n",
    "print(f\"üìä Dataset split:\")\n",
    "print(f\"   Training: {X_train.shape[0]} samples\")\n",
    "print(f\"   Testing: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge AI Model Development - Lightweight CNN Architecture\n",
    "print(\"üß† Building Edge-Optimized CNN Model...\")\n",
    "\n",
    "def create_edge_optimized_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a lightweight CNN optimized for edge deployment\n",
    "    Key optimizations:\n",
    "    - Fewer parameters\n",
    "    - Depthwise separable convolutions\n",
    "    - Efficient activation functions\n",
    "    - Minimal fully connected layers\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        # Input layer\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        \n",
    "        # First block - Feature extraction\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Second block - Depthwise separable for efficiency\n",
    "        tf.keras.layers.SeparableConv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Third block - Further feature extraction\n",
    "        tf.keras.layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Global pooling instead of flatten to reduce parameters\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Minimal dense layers\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "model = create_edge_optimized_model(input_shape, len(CATEGORIES))\n",
    "\n",
    "# Model summary\n",
    "print(\"üìã Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Calculate model size\n",
    "model_size_mb = model.count_params() * 4 / (1024 * 1024)  # Assuming float32\n",
    "print(f\"\\nüìè Model Statistics:\")\n",
    "print(f\"   Parameters: {model.count_params():,}\")\n",
    "print(f\"   Estimated size: {model_size_mb:.2f} MB\")\n",
    "\n",
    "# Compile with efficient optimizer for edge deployment\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "print(\"\\nüèãÔ∏è Training Edge AI Model...\")\n",
    "\n",
    "# Callbacks for training optimization\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n",
    "]\n",
    "\n",
    "# Training\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nüìä Model Performance:\")\n",
    "print(f\"   Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"   Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss plot\n",
    "ax2.plot(history.history['loss'], label='Training Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nüìà Detailed Classification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=CATEGORIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ffc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Lite Model Conversion and Optimization\n",
    "print(\"üîß Converting Model to TensorFlow Lite...\")\n",
    "\n",
    "def convert_to_tflite(model, quantization_type='dynamic'):\n",
    "    \"\"\"\n",
    "    Convert TensorFlow model to TensorFlow Lite with various optimization options\n",
    "    \"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    if quantization_type == 'dynamic':\n",
    "        # Dynamic range quantization (most common for edge)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        print(\"   Applying dynamic range quantization...\")\n",
    "        \n",
    "    elif quantization_type == 'float16':\n",
    "        # Float16 quantization\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "        print(\"   Applying float16 quantization...\")\n",
    "        \n",
    "    elif quantization_type == 'int8':\n",
    "        # Integer quantization (requires representative dataset)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_dataset_generator\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.uint8\n",
    "        converter.inference_output_type = tf.uint8\n",
    "        print(\"   Applying integer quantization...\")\n",
    "    \n",
    "    return converter.convert()\n",
    "\n",
    "def representative_dataset_generator():\n",
    "    \"\"\"\n",
    "    Generator for representative dataset used in integer quantization\n",
    "    \"\"\"\n",
    "    for i in range(100):\n",
    "        yield [X_train[i:i+1].astype(np.float32)]\n",
    "\n",
    "# Convert models with different quantization techniques\n",
    "models_dict = {}\n",
    "\n",
    "# 1. No quantization (baseline)\n",
    "print(\"\\n1Ô∏è‚É£ Converting without quantization...\")\n",
    "converter_baseline = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model_baseline = converter_baseline.convert()\n",
    "models_dict['baseline'] = tflite_model_baseline\n",
    "\n",
    "# 2. Dynamic range quantization\n",
    "print(\"\\n2Ô∏è‚É£ Converting with dynamic quantization...\")\n",
    "tflite_model_dynamic = convert_to_tflite(model, 'dynamic')\n",
    "models_dict['dynamic'] = tflite_model_dynamic\n",
    "\n",
    "# 3. Float16 quantization\n",
    "print(\"\\n3Ô∏è‚É£ Converting with float16 quantization...\")\n",
    "tflite_model_float16 = convert_to_tflite(model, 'float16')\n",
    "models_dict['float16'] = tflite_model_float16\n",
    "\n",
    "# Save models to files\n",
    "model_dir = \"tflite_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model_files = {}\n",
    "for name, tflite_model in models_dict.items():\n",
    "    file_path = os.path.join(model_dir, f\"recyclable_classifier_{name}.tflite\")\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    model_files[name] = file_path\n",
    "    \n",
    "    # Calculate model size\n",
    "    size_mb = len(tflite_model) / (1024 * 1024)\n",
    "    print(f\"   {name.capitalize()} model saved: {size_mb:.2f} MB\")\n",
    "\n",
    "print(f\"\\n‚úÖ All TensorFlow Lite models saved to '{model_dir}' directory\")\n",
    "\n",
    "# Model size comparison\n",
    "print(\"\\nüìä Model Size Comparison:\")\n",
    "sizes = {}\n",
    "for name, tflite_model in models_dict.items():\n",
    "    size_mb = len(tflite_model) / (1024 * 1024)\n",
    "    sizes[name] = size_mb\n",
    "    reduction = ((len(models_dict['baseline']) - len(tflite_model)) / len(models_dict['baseline'])) * 100\n",
    "    print(f\"   {name.capitalize()}: {size_mb:.2f} MB ({reduction:+.1f}% vs baseline)\")\n",
    "\n",
    "# Visualize size comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "names = list(sizes.keys())\n",
    "values = list(sizes.values())\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "bars = plt.bar(names, values, color=colors, alpha=0.8)\n",
    "plt.title('TensorFlow Lite Model Size Comparison', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Model Size (MB)', fontsize=12)\n",
    "plt.xlabel('Quantization Type', fontsize=12)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{value:.2f} MB', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test TensorFlow Lite model functionality\n",
    "def test_tflite_model(tflite_model_path, test_images, test_labels):\n",
    "    \"\"\"\n",
    "    Test TensorFlow Lite model performance\n",
    "    \"\"\"\n",
    "    # Load the TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # Get input and output details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    predictions = []\n",
    "    inference_times = []\n",
    "    \n",
    "    print(f\"   Testing {len(test_images)} samples...\")\n",
    "    \n",
    "    for i, img in enumerate(test_images[:50]):  # Test subset for speed\n",
    "        # Prepare input\n",
    "        input_data = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "        \n",
    "        # Run inference\n",
    "        start_time = time.time()\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        inference_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
    "        \n",
    "        predictions.append(output_data[0])\n",
    "        inference_times.append(inference_time)\n",
    "    \n",
    "    return np.array(predictions), np.array(inference_times)\n",
    "\n",
    "# Test all quantized models\n",
    "print(\"\\nüß™ Testing TensorFlow Lite Models Performance...\")\n",
    "\n",
    "model_performance = {}\n",
    "for name, file_path in model_files.items():\n",
    "    print(f\"\\n   Testing {name} model...\")\n",
    "    predictions, inference_times = test_tflite_model(file_path, X_test, y_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    pred_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test[:len(predictions)], axis=1)\n",
    "    accuracy = np.mean(pred_classes == true_classes)\n",
    "    \n",
    "    # Calculate average inference time\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    \n",
    "    model_performance[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'avg_inference_time': avg_inference_time,\n",
    "        'model_size': sizes[name]\n",
    "    }\n",
    "    \n",
    "    print(f\"      Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"      Avg Inference Time: {avg_inference_time:.2f} ms\")\n",
    "\n",
    "print(\"\\nüìã Performance Summary:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Model':<12} {'Accuracy':<12} {'Inference (ms)':<15} {'Size (MB)':<10}\")\n",
    "print(\"-\" * 70)\n",
    "for name, perf in model_performance.items():\n",
    "    print(f\"{name.capitalize():<12} {perf['accuracy']:<12.4f} {perf['avg_inference_time']:<15.2f} {perf['model_size']:<10.2f}\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd87c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge AI Deployment Simulation and Real-Time Analysis\n",
    "print(\"üöÄ Simulating Edge AI Deployment Scenarios...\")\n",
    "\n",
    "class EdgeAISimulator:\n",
    "    \"\"\"\n",
    "    Simulate edge device deployment scenarios with different constraints\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tflite_model_path):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "        \n",
    "    def process_batch(self, images, batch_size=1):\n",
    "        \"\"\"\n",
    "        Process images in batches to simulate real-time processing\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        times = []\n",
    "        \n",
    "        for i in range(0, len(images), batch_size):\n",
    "            batch = images[i:i + batch_size]\n",
    "            batch_results = []\n",
    "            \n",
    "            start_time = time.time()\n",
    "            for img in batch:\n",
    "                # Prepare input\n",
    "                input_data = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "                \n",
    "                # Run inference\n",
    "                self.interpreter.set_tensor(self.input_details[0]['index'], input_data)\n",
    "                self.interpreter.invoke()\n",
    "                output = self.interpreter.get_tensor(self.output_details[0]['index'])\n",
    "                \n",
    "                # Get prediction\n",
    "                predicted_class = np.argmax(output[0])\n",
    "                confidence = np.max(output[0])\n",
    "                \n",
    "                batch_results.append({\n",
    "                    'class': predicted_class,\n",
    "                    'confidence': confidence,\n",
    "                    'class_name': CATEGORIES[predicted_class]\n",
    "                })\n",
    "            \n",
    "            processing_time = (time.time() - start_time) * 1000  # ms\n",
    "            results.extend(batch_results)\n",
    "            times.append(processing_time)\n",
    "            \n",
    "        return results, times\n",
    "\n",
    "# Device simulation scenarios\n",
    "device_scenarios = {\n",
    "    'raspberry_pi_4': {\n",
    "        'name': 'Raspberry Pi 4',\n",
    "        'cpu_cores': 4,\n",
    "        'memory_mb': 4096,\n",
    "        'target_fps': 10,\n",
    "        'description': 'Low-power edge device for IoT applications'\n",
    "    },\n",
    "    'mobile_phone': {\n",
    "        'name': 'Modern Smartphone',\n",
    "        'cpu_cores': 8,\n",
    "        'memory_mb': 8192,\n",
    "        'target_fps': 30,\n",
    "        'description': 'Mobile deployment for consumer apps'\n",
    "    },\n",
    "    'edge_tpu': {\n",
    "        'name': 'Edge TPU Device',\n",
    "        'cpu_cores': 4,\n",
    "        'memory_mb': 2048,\n",
    "        'target_fps': 60,\n",
    "        'description': 'Specialized AI acceleration hardware'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Test deployment scenarios\n",
    "print(\"\\nüñ•Ô∏è Testing Deployment Scenarios...\")\n",
    "\n",
    "# Use the dynamic quantized model for deployment simulation\n",
    "simulator = EdgeAISimulator(model_files['dynamic'])\n",
    "\n",
    "# Test with different batch sizes and scenarios\n",
    "test_sample_size = 100\n",
    "test_images = X_test[:test_sample_size]\n",
    "\n",
    "deployment_results = {}\n",
    "\n",
    "for scenario_name, scenario_config in device_scenarios.items():\n",
    "    print(f\"\\nüì± Testing on {scenario_config['name']}...\")\n",
    "    \n",
    "    # Simulate processing\n",
    "    results, processing_times = simulator.process_batch(test_images, batch_size=1)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    avg_inference_time = np.mean(processing_times)\n",
    "    max_fps = 1000 / avg_inference_time if avg_inference_time > 0 else 0\n",
    "    target_fps = scenario_config['target_fps']\n",
    "    fps_performance = min(max_fps / target_fps, 1.0) * 100\n",
    "    \n",
    "    # Memory estimation (simplified)\n",
    "    estimated_memory_usage = sizes['dynamic'] * 2  # Model + buffers\n",
    "    memory_efficiency = (1 - estimated_memory_usage / scenario_config['memory_mb']) * 100\n",
    "    \n",
    "    deployment_results[scenario_name] = {\n",
    "        'avg_inference_time': avg_inference_time,\n",
    "        'max_fps': max_fps,\n",
    "        'target_fps': target_fps,\n",
    "        'fps_performance': fps_performance,\n",
    "        'memory_efficiency': memory_efficiency,\n",
    "        'config': scenario_config\n",
    "    }\n",
    "    \n",
    "    print(f\"   Average inference time: {avg_inference_time:.2f} ms\")\n",
    "    print(f\"   Maximum FPS: {max_fps:.1f}\")\n",
    "    print(f\"   Target FPS: {target_fps}\")\n",
    "    print(f\"   FPS Performance: {fps_performance:.1f}%\")\n",
    "    print(f\"   Memory efficiency: {memory_efficiency:.1f}%\")\n",
    "\n",
    "# Visualize deployment performance\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "scenarios = list(deployment_results.keys())\n",
    "scenario_names = [deployment_results[s]['config']['name'] for s in scenarios]\n",
    "\n",
    "# 1. Inference Time Comparison\n",
    "inference_times = [deployment_results[s]['avg_inference_time'] for s in scenarios]\n",
    "ax1.bar(scenario_names, inference_times, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax1.set_title('Average Inference Time by Device', fontweight='bold')\n",
    "ax1.set_ylabel('Time (ms)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. FPS Performance\n",
    "max_fps_values = [deployment_results[s]['max_fps'] for s in scenarios]\n",
    "target_fps_values = [deployment_results[s]['target_fps'] for s in scenarios]\n",
    "\n",
    "x_pos = np.arange(len(scenarios))\n",
    "width = 0.35\n",
    "\n",
    "ax2.bar(x_pos - width/2, max_fps_values, width, label='Achieved FPS', color='#4ECDC4')\n",
    "ax2.bar(x_pos + width/2, target_fps_values, width, label='Target FPS', color='#FF6B6B', alpha=0.7)\n",
    "ax2.set_title('FPS Performance Comparison', fontweight='bold')\n",
    "ax2.set_ylabel('Frames Per Second')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(scenario_names, rotation=45)\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Performance Score\n",
    "fps_scores = [deployment_results[s]['fps_performance'] for s in scenarios]\n",
    "memory_scores = [deployment_results[s]['memory_efficiency'] for s in scenarios]\n",
    "\n",
    "ax3.bar(x_pos - width/2, fps_scores, width, label='FPS Performance', color='#45B7D1')\n",
    "ax3.bar(x_pos + width/2, memory_scores, width, label='Memory Efficiency', color='#96CEB4')\n",
    "ax3.set_title('Performance Scores (%)', fontweight='bold')\n",
    "ax3.set_ylabel('Score (%)')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(scenario_names, rotation=45)\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Deployment Suitability Radar Chart\n",
    "def create_radar_chart(ax, scenario_name):\n",
    "    categories = ['Inference Speed', 'FPS Performance', 'Memory Efficiency', 'Power Efficiency']\n",
    "    \n",
    "    # Normalize scores to 0-100 scale\n",
    "    scores = [\n",
    "        100 - (deployment_results[scenario_name]['avg_inference_time'] / 50 * 100),  # Inverse of inference time\n",
    "        deployment_results[scenario_name]['fps_performance'],\n",
    "        deployment_results[scenario_name]['memory_efficiency'],\n",
    "        85  # Simulated power efficiency score\n",
    "    ]\n",
    "    \n",
    "    # Ensure scores are between 0-100\n",
    "    scores = [max(0, min(100, score)) for score in scores]\n",
    "    \n",
    "    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "    scores += scores[:1]  # Complete the circle\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax.plot(angles, scores, 'o-', linewidth=2, label=deployment_results[scenario_name]['config']['name'])\n",
    "    ax.fill(angles, scores, alpha=0.25)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_title(f\"Deployment Profile: {deployment_results[scenario_name]['config']['name']}\", fontweight='bold')\n",
    "    ax.grid(True)\n",
    "\n",
    "# Create radar chart for the best performing scenario\n",
    "best_scenario = max(scenarios, key=lambda s: deployment_results[s]['fps_performance'])\n",
    "create_radar_chart(ax4, best_scenario)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Real-time processing simulation\n",
    "print(\"\\n‚ö° Real-Time Processing Simulation...\")\n",
    "\n",
    "def simulate_real_time_processing(num_frames=30, target_fps=10):\n",
    "    \"\"\"\n",
    "    Simulate real-time recyclable item classification\n",
    "    \"\"\"\n",
    "    print(f\"   Simulating {num_frames} frames at {target_fps} FPS target...\")\n",
    "    \n",
    "    frame_interval = 1.0 / target_fps  # Time between frames in seconds\n",
    "    \n",
    "    results = []\n",
    "    actual_times = []\n",
    "    \n",
    "    for frame_id in range(num_frames):\n",
    "        # Simulate frame capture\n",
    "        frame_start = time.time()\n",
    "        \n",
    "        # Get random test image\n",
    "        img_idx = np.random.randint(0, len(X_test))\n",
    "        test_img = X_test[img_idx]\n",
    "        true_class = np.argmax(y_test[img_idx])\n",
    "        \n",
    "        # Process with edge AI\n",
    "        input_data = np.expand_dims(test_img, axis=0).astype(np.float32)\n",
    "        \n",
    "        processing_start = time.time()\n",
    "        simulator.interpreter.set_tensor(simulator.input_details[0]['index'], input_data)\n",
    "        simulator.interpreter.invoke()\n",
    "        output = simulator.interpreter.get_tensor(simulator.output_details[0]['index'])\n",
    "        processing_time = (time.time() - processing_start) * 1000\n",
    "        \n",
    "        predicted_class = np.argmax(output[0])\n",
    "        confidence = np.max(output[0])\n",
    "        \n",
    "        # Check if prediction is correct\n",
    "        is_correct = predicted_class == true_class\n",
    "        \n",
    "        results.append({\n",
    "            'frame_id': frame_id,\n",
    "            'predicted_class': CATEGORIES[predicted_class],\n",
    "            'true_class': CATEGORIES[true_class],\n",
    "            'confidence': confidence,\n",
    "            'is_correct': is_correct,\n",
    "            'processing_time': processing_time\n",
    "        })\n",
    "        \n",
    "        # Calculate frame timing\n",
    "        frame_end = time.time()\n",
    "        frame_duration = frame_end - frame_start\n",
    "        actual_times.append(frame_duration)\n",
    "        \n",
    "        # Simulate real-time constraint\n",
    "        if frame_duration < frame_interval:\n",
    "            time.sleep(frame_interval - frame_duration)\n",
    "    \n",
    "    return results, actual_times\n",
    "\n",
    "# Run real-time simulation\n",
    "simulation_results, frame_times = simulate_real_time_processing(30, 10)\n",
    "\n",
    "# Analyze simulation results\n",
    "accuracy = np.mean([r['is_correct'] for r in simulation_results])\n",
    "avg_confidence = np.mean([r['confidence'] for r in simulation_results])\n",
    "avg_processing_time = np.mean([r['processing_time'] for r in simulation_results])\n",
    "avg_frame_time = np.mean(frame_times) * 1000  # Convert to ms\n",
    "\n",
    "print(f\"\\nüìä Real-Time Simulation Results:\")\n",
    "print(f\"   Accuracy: {accuracy:.2%}\")\n",
    "print(f\"   Average Confidence: {avg_confidence:.3f}\")\n",
    "print(f\"   Average Processing Time: {avg_processing_time:.2f} ms\")\n",
    "print(f\"   Average Frame Time: {avg_frame_time:.2f} ms\")\n",
    "print(f\"   Achieved FPS: {1000/avg_frame_time:.1f}\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(f\"\\nüîç Sample Real-Time Predictions:\")\n",
    "for i, result in enumerate(simulation_results[:5]):\n",
    "    status = \"‚úÖ\" if result['is_correct'] else \"‚ùå\"\n",
    "    print(f\"   Frame {result['frame_id']}: {result['predicted_class']} \"\n",
    "          f\"(confidence: {result['confidence']:.3f}) {status}\")\n",
    "\n",
    "print(f\"\\nüéØ Edge AI Benefits Summary:\")\n",
    "print(f\"   ‚úÖ Low Latency: {avg_processing_time:.1f}ms per inference\")\n",
    "print(f\"   ‚úÖ Privacy: All processing done locally\")\n",
    "print(f\"   ‚úÖ Offline Capability: No internet required\")\n",
    "print(f\"   ‚úÖ Real-time Performance: {1000/avg_frame_time:.1f} FPS achieved\")\n",
    "print(f\"   ‚úÖ Small Model Size: {sizes['dynamic']:.2f} MB\")\n",
    "print(f\"   ‚úÖ Energy Efficient: Optimized for edge devices\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
